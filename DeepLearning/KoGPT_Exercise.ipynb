{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ì¹´ì¹´ì˜¤ë¸Œë ˆì¸ì˜ KoGPTëŠ”Colab Proë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”í•œ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì‘ë™ ì•ˆë¨\n",
        "kakaobrain/kogpt\n",
        "https://huggingface.co/kakaobrain/kogpt\n",
        "\n",
        "# SKTì˜ KoGPTë¥¼ ì‚¬ìš©í•¨\n",
        "skt/kogpt2-base-v2\n",
        "https://github.com/SKT-AI/KoGPT2\n",
        "\n",
        "skt/ko-gpt-trinity-1.2B-v0.5\n",
        "https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5/blob/main/README.md\n"
      ],
      "metadata": {
        "id": "sPvHsukCKiwj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc4ga8D4mu2f",
        "outputId": "3e8bb71f-547d-4e68-b35b-48bc3d85afc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 15 15:38:44 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "8ghUJtQwnDl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7102bf-9893-4ce3-8736-408210283b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SKT Ko-GPT í† í¬ë‚˜ì´ì €\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "tokenizer.tokenize(\"ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ì…ë‹ˆë‹¤.ğŸ˜¤:)l^o\")"
      ],
      "metadata": {
        "id": "EfI8tRnEye2G",
        "outputId": "972082d7-a5ee-420e-de4e-b310d3f0103f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['â–ì•ˆë…•',\n",
              " 'í•˜',\n",
              " 'ì„¸',\n",
              " 'ìš”.',\n",
              " 'â–í•œêµ­ì–´',\n",
              " 'â–G',\n",
              " 'P',\n",
              " 'T',\n",
              " '-2',\n",
              " 'â–ì…',\n",
              " 'ë‹ˆë‹¤.',\n",
              " 'ğŸ˜¤',\n",
              " ':)',\n",
              " 'l^o']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SKT Ko-GPT ëª¨ë¸\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = 'ì¸ê³µì§€ëŠ¥ì„ ë°°ìš°ê¸° ìœ„í•´ì„œëŠ”'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=128,\n",
        "                           repetition_penalty=2.0,\n",
        "                           do_sample=True, top_k=50, top_p=0.95,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqlmv4j6yIXB",
        "outputId": "453f31b1-f5e2-4ad3-976f-dc2d7fc8b6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¸ê³µì§€ëŠ¥ì„ ë°°ìš°ê¸° ìœ„í•´ì„œëŠ” ìˆ˜í•™ê³¼ ê³¼í•™, ì¸ë¬¸, ì‚¬íšŒ, ë¬¸í•™ ë“± ëª¨ë“  í•™ë¬¸ì˜ ê¸°ì´ˆì§€ì‹ì„ ìµí í•„ìš”ê°€ ìˆë‹¤.\n",
            "ì´ëŸ¬í•œ ì´ìœ ë“¤ì„ í† ëŒ€ë¡œ í•™ìƒë“¤ì€ ìˆ˜í•™ ê´€ë ¨ ê³¼ëª©ì´ë‚˜ ì‘ìš©ê³¼ëª©ì— ëŒ€í•œ ì§€ì‹ì„ ìŒ“ì„ ë¿ë§Œ ì•„ë‹ˆë¼ ìì‹ ì˜ ì ì„±ì— ë§ëŠ” ê³µë¶€ ë°©ë²•ì„ ì°¾ë„ë¡ í•˜ëŠ” ê²ƒì€ ë¬¼ë¡ ì´ë‹¤.\n",
            "ë§ì€ í•™êµë“¤ì´ í•™ìƒë“¤ì„ ìœ„í•œ ê°ì¢… í”„ë¡œê·¸ë¨ë¶€í„° í•™ì›ê¹Œì§€ ë‹¤ì–‘í•œ í”„ë¡œê·¸ë¨ì„ ìš´ì˜í•˜ë©° í•™ìƒë“¤ì—ê²Œ ìˆ˜ì¤€ ë†’ì€ ìˆ˜ì—…ì„ ì œê³µí•˜ê³  ìˆê¸° ë•Œë¬¸ì´ë‹¤.\n",
            "ë”°ë¼ì„œ ë³´ë‹¤ ë‚˜ì€ í•™ìŠµì„ ìœ„í•´ í•™ìƒë“¤ì´ ì›í•˜ëŠ” ëŒ€í•™ê³¼ í•™ì›ì„ ì°¾ëŠ” ì¼ì´ ê²°ì½” ì‰½ì§€ëŠ” ì•Šì„ ê²ƒì´ë‹¤.\n",
            "ê·¸ëŸ¬ë‚˜ ë§ì€ ëŒ€í•™ë“¤ì€ ì´ëŸ¬í•œ êµìœ¡ì—¬ê±´ì„ ê°–ì¶”ê³  ìˆëŠ” ë°˜ë©´ ìš°ë¦¬ ì‚¬íšŒì—ì„œ ê²½ìŸí•˜ê³  ìˆì§€ ì•Šì€ ì¼ë¶€ ëŒ€í•™ì˜ ê²½ìš° ì‚¬êµìœ¡ì´ ì„±í–‰í•  ê°€ëŠ¥ì„±ë„ ë°°ì œí•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
            "ê³µêµìœ¡ì€ í•™ìƒë“¤ì˜ í•™ìŠµëŠ¥ë ¥ í–¥ìƒê³¼ ìê¸°\n"
          ]
        }
      ]
    }
  ]
}